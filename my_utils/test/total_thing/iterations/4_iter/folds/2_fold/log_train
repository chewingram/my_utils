MTPR from /Users/samuel/Work/codes/python_packages/my_utils/my_utils/test/total_thing/iterations/4_iter/folds/2_fold/init.mtp, Database: /Users/samuel/Work/codes/python_packages/my_utils/my_utils/test/total_thing/iterations/4_iter/folds/2_fold/TrainSet.cfg
Random initialization of radial coefficients
Rescaling...
   scaling = 0.833333333333333, condition number = 338961.542520522
   scaling = 0.909090909090909, condition number = 369776.856065191
   scaling = 1, condition number = 406754.541669837
   scaling = 1.1, condition number = 447429.995837065
   scaling = 1.2, condition number = 488105.449993335
Rescaling to 0.833333333333333... done
Rescaling...
   scaling = 0.694444444444445, condition number = 282468.431727357
   scaling = 0.757575757575758, condition number = 308147.380059544
   scaling = 0.833333333333333, condition number = 338962.118067647
   scaling = 0.916666666666667, condition number = 372858.329867623
   scaling = 1, condition number = 406754.541670551
Rescaling to 0.694444444444445... done
Rescaling...
   scaling = 0.578703703703704, condition number = 235390.359781322
   scaling = 0.631313131313131, condition number = 256789.483394301
   scaling = 0.694444444444445, condition number = 282468.431727357
   scaling = 0.763888888888889, condition number = 310715.274895066
   scaling = 0.833333333333333, condition number = 338962.118067647
Rescaling to 0.578703703703704... done
Rescaling...
   scaling = 0.482253086419753, condition number = 196158.633159671
   scaling = 0.526094276094276, condition number = 213991.236166595
   scaling = 0.578703703703704, condition number = 235390.359781322
   scaling = 0.636574074074074, condition number = 258929.395753471
   scaling = 0.694444444444445, condition number = 282468.431727357
Rescaling to 0.482253086419753... done
Rescaling...
   scaling = 0.401877572016461, condition number = 158168.424778001
   scaling = 0.43841189674523, condition number = 178326.030151975
   scaling = 0.482253086419753, condition number = 196158.633159671
   scaling = 0.530478395061729, condition number = 215774.496468364
   scaling = 0.578703703703704, condition number = 235390.359781322
Rescaling to 0.401877572016461... done
Rescaling...
   scaling = 0.334897976680384, condition number = 109839.183886513
   scaling = 0.365343247287692, condition number = 130717.706435398
   scaling = 0.401877572016461, condition number = 158168.424778001
   scaling = 0.442065329218107, condition number = 179812.080404542
   scaling = 0.482253086419753, condition number = 196158.633159801
Rescaling to 0.334897976680384... done
Rescaling...
   scaling = 0.279081647233653, condition number = 76277.2110463987
   scaling = 0.304452706073077, condition number = 90776.1850379192
   scaling = 0.334897976680384, condition number = 109839.183886513
   scaling = 0.368387774348423, condition number = 132905.4124938
   scaling = 0.401877572016461, condition number = 158168.424778001
Rescaling to 0.279081647233653... done
Rescaling...
   scaling = 0.232568039361378, condition number = 52970.285464418
   scaling = 0.25371058839423, condition number = 63039.0174023278
   scaling = 0.279081647233653, condition number = 76277.2110463987
   scaling = 0.306989811957019, condition number = 92295.4253562515
   scaling = 0.334897976680384, condition number = 109839.183886513
Rescaling to 0.232568039361378... done
Rescaling...
   scaling = 0.193806699467815, condition number = 36784.9204792288
   scaling = 0.211425490328525, condition number = 43777.0954349265
   scaling = 0.232568039361378, condition number = 52970.285464418
   scaling = 0.255824843297516, condition number = 64094.0454010369
   scaling = 0.279081647233653, condition number = 76277.2110463987
Rescaling to 0.193806699467815... done
Rescaling...
   scaling = 0.161505582889846, condition number = 25545.0836871068
   scaling = 0.176187908607104, condition number = 30400.7607379662
   scaling = 0.193806699467815, condition number = 36784.9204792288
   scaling = 0.213187369414596, condition number = 44509.7537673406
   scaling = 0.232568039361378, condition number = 52970.285464418
Rescaling to 0.161505582889846... done
Rescaling...
   scaling = 0.134587985741538, condition number = 17739.6414748336
   scaling = 0.146823257172587, condition number = 21111.6394244895
   scaling = 0.161505582889846, condition number = 25545.0836871068
   scaling = 0.17765614117883, condition number = 30909.5512464171
   scaling = 0.193806699467815, condition number = 36784.9204792213
Rescaling to 0.134587985741538... done
Rescaling...
   scaling = 0.112156654784615, condition number = 13906.4437820979
   scaling = 0.122352714310489, condition number = 15170.6659223
   scaling = 0.134587985741538, condition number = 17739.6414748336
   scaling = 0.148046784315692, condition number = 21464.9661662614
   scaling = 0.161505582889846, condition number = 25545.0836871068
Rescaling to 0.112156654784615... done
Rescaling...
   scaling = 0.0934638789871793, condition number = 11588.7032078365
   scaling = 0.101960595258741, condition number = 12642.2216472538
   scaling = 0.112156654784615, condition number = 13906.4437820979
   scaling = 0.123372320263077, condition number = 15297.0881365356
   scaling = 0.134587985741538, condition number = 17739.6414748336
Rescaling to 0.0934638789871793... done
Rescaling...
   scaling = 0.0778865658226494, condition number = 9657.25276261566
   scaling = 0.0849671627156175, condition number = 10535.1847774208
   scaling = 0.0934638789871793, condition number = 11588.7032078365
   scaling = 0.102810266885897, condition number = 12747.573491585
   scaling = 0.112156654784615, condition number = 13906.4437820979
Rescaling to 0.0778865658226494... done
Rescaling...
   scaling = 0.0649054715188745, condition number = 8047.71078101268
   scaling = 0.0708059689296813, condition number = 8779.32076293818
   scaling = 0.0778865658226494, condition number = 9657.25276261566
   scaling = 0.0856752224049144, condition number = 10622.9779795222
   scaling = 0.0934638789871793, condition number = 11588.7032078342
Rescaling to 0.0649054715188745... done
Rescaling...
   scaling = 0.0540878929323954, condition number = 6706.42589153957
   scaling = 0.0590049741080677, condition number = 7316.10082469179
   scaling = 0.0649054715188745, condition number = 8047.71078101268
   scaling = 0.071396018670762, condition number = 8852.48176215255
   scaling = 0.0778865658226494, condition number = 9657.25276261845
Rescaling to 0.0540878929323954... done
Rescaling...
   scaling = 0.0450732441103295, condition number = 5588.68864629301
   scaling = 0.0491708117567231, condition number = 6096.75100207494
   scaling = 0.0540878929323954, condition number = 6706.42589153957
   scaling = 0.059496682225635, condition number = 7377.06831979577
   scaling = 0.0649054715188745, condition number = 8047.71078101268
Rescaling to 0.0450732441103295... done
Rescaling...
   scaling = 0.0375610367586079, condition number = 4657.24122123092
   scaling = 0.0409756764639359, condition number = 5080.62636554566
   scaling = 0.0450732441103295, condition number = 5588.68864629301
   scaling = 0.0495805685213625, condition number = 6147.55724066151
   scaling = 0.0540878929323954, condition number = 6706.42589154351
Rescaling to 0.0375610367586079... done
Rescaling...
   scaling = 0.0313008639655066, condition number = 3881.03551528179
   scaling = 0.03414639705328, condition number = 4233.85620625736
   scaling = 0.0375610367586079, condition number = 4657.24122123092
   scaling = 0.0413171404344687, condition number = 5122.96488511607
   scaling = 0.0450732441103295, condition number = 5588.68864629301
Rescaling to 0.0313008639655066... done
Rescaling...
   scaling = 0.0260840533045889, condition number = 3234.19826084202
   scaling = 0.0284553308777333, condition number = 3528.21504820025
   scaling = 0.0313008639655066, condition number = 3881.03551528179
   scaling = 0.0344309503620573, condition number = 4269.13828425913
   scaling = 0.0375610367586079, condition number = 4657.24122123092
Rescaling to 0.0260840533045889... done
Rescaling...
   scaling = 0.0217367110871574, condition number = 2695.16866510657
   scaling = 0.0237127757314444, condition number = 2940.18186258737
   scaling = 0.0260840533045889, condition number = 3234.19826084202
   scaling = 0.0286924586350477, condition number = 3557.61674241098
   scaling = 0.0313008639655066, condition number = 3881.03551528179
Rescaling to 0.0217367110871574... done
Rescaling...
   scaling = 0.0181139259059645, condition number = 2028.51765897618
   scaling = 0.0197606464428703, condition number = 2450.15614718643
   scaling = 0.0217367110871574, condition number = 2695.16866510657
   scaling = 0.0239103821958731, condition number = 2964.68320928387
   scaling = 0.0260840533045889, condition number = 3234.19826084202
Rescaling to 0.0181139259059645... done
Rescaling...
   scaling = 0.0150949382549704, condition number = 1173.91722588793
   scaling = 0.0164672053690586, condition number = 1524.0590007058
   scaling = 0.0181139259059645, condition number = 2028.51765897618
   scaling = 0.0199253184965609, condition number = 2470.57382233729
   scaling = 0.0217367110871574, condition number = 2695.16866510499
Rescaling to 0.0150949382549704... done
Rescaling...
   scaling = 0.0125791152124753, condition number = 679.358227765031
   scaling = 0.0137226711408822, condition number = 881.985841049217
   scaling = 0.0150949382549704, condition number = 1173.91722588793
   scaling = 0.0166044320804674, condition number = 1562.47848256312
   scaling = 0.0181139259059645, condition number = 2028.51765897618
Rescaling to 0.0125791152124753... done
Rescaling...
   scaling = 0.0104825960103961, condition number = 393.156941301605
   scaling = 0.0114355592840685, condition number = 510.41735636759
   scaling = 0.0125791152124753, condition number = 679.358227765031
   scaling = 0.0138370267337229, condition number = 904.219272249899
   scaling = 0.0150949382549704, condition number = 1173.91722588793
Rescaling to 0.0104825960103961... done
Rescaling...
   scaling = 0.00873549667533009, condition number = 227.533592453909
   scaling = 0.00952963273672374, condition number = 295.391402978997
   scaling = 0.0104825960103961, condition number = 393.156941301605
   scaling = 0.0115308556114357, condition number = 523.283842015821
   scaling = 0.0125791152124753, condition number = 679.358227765031
Rescaling to 0.00873549667533009... done
Rescaling...
   scaling = 0.00727958056277508, condition number = 131.689948461696
   scaling = 0.00794136061393645, condition number = 170.95786571378
   scaling = 0.00873549667533009, condition number = 227.533592453909
   scaling = 0.00960904634286311, condition number = 302.837177288685
   scaling = 0.0104825960103961, condition number = 393.156941301605
Rescaling to 0.00727958056277508... done
Rescaling...
   scaling = 0.0060663171356459, condition number = 76.2292796485589
   scaling = 0.00661780051161371, condition number = 98.951484253954
   scaling = 0.00727958056277508, condition number = 131.689948461696
   scaling = 0.00800753861905259, condition number = 175.266617892651
   scaling = 0.00873549667533009, condition number = 227.533592453909
Rescaling to 0.0060663171356459... done
Rescaling...
   scaling = 0.00505526427970492, condition number = 44.1402333161402
   scaling = 0.00551483375967809, condition number = 57.2863905315598
   scaling = 0.0060663171356459, condition number = 76.2292796485589
   scaling = 0.00667294884921049, condition number = 101.444775872736
   scaling = 0.00727958056277508, condition number = 131.689948461696
Rescaling to 0.00505526427970492... done
Rescaling...
   scaling = 0.00421272023308743, condition number = 25.5793342828522
   scaling = 0.00459569479973174, condition number = 33.1822447009177
   scaling = 0.00505526427970492, condition number = 44.1402333161402
   scaling = 0.00556079070767541, condition number = 58.7289851728364
   scaling = 0.0060663171356459, condition number = 76.2292796485589
Rescaling to 0.00421272023308743... done
Rescaling...
   scaling = 0.00351060019423953, condition number = 14.8518652958968
   scaling = 0.00382974566644312, condition number = 19.244389269658
   scaling = 0.00421272023308743, condition number = 25.5793342828522
   scaling = 0.00463399225639617, condition number = 34.0166662428617
   scaling = 0.00505526427970492, condition number = 44.1402333161402
Rescaling to 0.00351060019423953... done
Rescaling...
   scaling = 0.00292550016186627, condition number = 8.6650749383972
   scaling = 0.00319145472203593, condition number = 11.1957496187208
   scaling = 0.00351060019423953, condition number = 14.8518652958968
   scaling = 0.00386166021366348, condition number = 19.726649537462
   scaling = 0.00421272023308743, condition number = 25.5793342828522
Rescaling to 0.00292550016186627... done
Rescaling...
   scaling = 0.00243791680155523, condition number = 6.02346284778962
   scaling = 0.00265954560169661, condition number = 7.08272110619927
   scaling = 0.00292550016186627, condition number = 8.6650749383972
   scaling = 0.0032180501780529, condition number = 11.4738768556591
   scaling = 0.00351060019423953, condition number = 14.8518652958968
Rescaling to 0.00243791680155523... done
Rescaling...
   scaling = 0.00203159733462936, condition number = 4.39890797339706
   scaling = 0.00221628800141384, condition number = 5.08266960816961
   scaling = 0.00243791680155523, condition number = 6.02346284778962
   scaling = 0.00268170848171075, condition number = 7.19481400009025
   scaling = 0.00292550016186627, condition number = 8.6650749383972
Rescaling to 0.00203159733462936... done
Rescaling...
   scaling = 0.0016929977788578, condition number = 3.43056532067615
   scaling = 0.00184690666784487, condition number = 3.81970464613649
   scaling = 0.00203159733462936, condition number = 4.39890797339706
   scaling = 0.00223475706809229, condition number = 5.15625672722863
   scaling = 0.00243791680155523, condition number = 6.02346284779123
Rescaling to 0.0016929977788578... done
Rescaling...
   scaling = 0.0014108314823815, condition number = 3.16862861269858
   scaling = 0.00153908888987072, condition number = 3.1423466996752
   scaling = 0.0016929977788578, condition number = 3.43056532067615
   scaling = 0.00186229755674358, condition number = 3.86355714991076
   scaling = 0.00203159733462936, condition number = 4.39890797339706
Rescaling to 0.00153908888987072... done
Rescaling...
   scaling = 0.00128257407489227, condition number = 3.761442143928
   scaling = 0.00139917171806429, condition number = 3.21177754255028
   scaling = 0.00153908888987072, condition number = 3.1423466996752
   scaling = 0.0016929977788578, condition number = 3.43056532067041
   scaling = 0.00184690666784487, condition number = 3.81970464613563
Rescaling to 0.00153908888987072... done
Pre-training started
MTPR parallel training started
BFGS iter 0: f=0.731663
BFGS iter 1: f=0.680739
BFGS iter 2: f=0.618794
BFGS iter 3: f=0.560587
BFGS iter 4: f=0.517057
BFGS iter 5: f=0.478407
BFGS iter 6: f=0.405812
BFGS iter 7: f=0.369297
BFGS iter 8: f=0.316328
BFGS iter 9: f=0.278965
BFGS iter 10: f=0.200457
BFGS iter 11: f=0.180903
BFGS iter 12: f=0.174401
BFGS iter 13: f=0.170298
BFGS iter 14: f=0.156934
BFGS iter 15: f=0.143118
BFGS iter 16: f=0.132145
BFGS iter 17: f=0.124284
BFGS iter 18: f=0.117932
BFGS iter 19: f=0.112617
BFGS iter 20: f=0.103011
BFGS iter 21: f=0.096002
BFGS iter 22: f=0.0909902
BFGS iter 23: f=0.0885716
BFGS iter 24: f=0.0876475
BFGS iter 25: f=0.0856847
BFGS iter 26: f=0.0843722
BFGS iter 27: f=0.0828518
BFGS iter 28: f=0.0816153
BFGS iter 29: f=0.0800528
BFGS iter 30: f=0.0790778
BFGS iter 31: f=0.077704
BFGS iter 32: f=0.0763059
BFGS iter 33: f=0.0731204
BFGS iter 34: f=0.0713566
BFGS iter 35: f=0.0708243
BFGS iter 36: f=0.0703428
BFGS iter 37: f=0.0697205
BFGS iter 38: f=0.0690609
BFGS iter 39: f=0.0687948
BFGS iter 40: f=0.0684047
BFGS iter 41: f=0.0678822
BFGS iter 42: f=0.0674209
BFGS iter 43: f=0.0671852
BFGS iter 44: f=0.0669813
BFGS iter 45: f=0.0666868
BFGS iter 46: f=0.0664091
BFGS iter 47: f=0.0660918
BFGS iter 48: f=0.0654707
BFGS iter 49: f=0.0640662
BFGS iter 50: f=0.0632392
BFGS iter 51: f=0.063029
BFGS iter 52: f=0.0623105
BFGS iter 53: f=0.061081
BFGS iter 54: f=0.0595335
BFGS iter 55: f=0.0587431
BFGS iter 56: f=0.0566702
BFGS iter 57: f=0.0551548
BFGS iter 58: f=0.052701
BFGS iter 59: f=0.052048
BFGS iter 60: f=0.0511128
BFGS iter 61: f=0.05079
BFGS iter 62: f=0.0503869
BFGS iter 63: f=0.0494397
BFGS iter 64: f=0.0487885
BFGS iter 65: f=0.0482713
BFGS iter 66: f=0.0478218
BFGS iter 67: f=0.0473867
BFGS iter 68: f=0.0468324
BFGS iter 69: f=0.0464553
BFGS iter 70: f=0.0455576
BFGS iter 71: f=0.0451913
BFGS iter 72: f=0.044963
BFGS iter 73: f=0.0448744
BFGS iter 74: f=0.0445992
step limit reached
MTPR training ended
Rescaling...
   scaling = 0.00128257407489227, condition number = 52.7606829726498
   scaling = 0.00139917171806429, condition number = 40.8182107588223
   scaling = 0.00153908888987072, condition number = 30.8338113322276
   scaling = 0.0016929977788578, condition number = 23.32049803746
   scaling = 0.00184690666784487, condition number = 18.1035845809479
Rescaling to 0.00184690666784487... done
Rescaling...
   scaling = 0.00153908888987072, condition number = 30.8338113232208
   scaling = 0.00167900606167715, condition number = 23.8929321804509
   scaling = 0.00184690666784487, condition number = 18.1035845835227
   scaling = 0.00203159733462936, condition number = 13.7586022502065
   scaling = 0.00221628800141384, condition number = 10.7525313480401
Rescaling to 0.00221628800141384... done
Rescaling...
   scaling = 0.00184690666784487, condition number = 18.1035845777793
   scaling = 0.00201480727401258, condition number = 14.0891305953805
   scaling = 0.00221628800141384, condition number = 10.75253134804
   scaling = 0.00243791680155523, condition number = 8.26330679425797
   scaling = 0.00265954560169661, condition number = 6.55736599095459
Rescaling to 0.00265954560169661... done
Rescaling...
   scaling = 0.00221628800141384, condition number = 10.7525313480407
   scaling = 0.0024177687288151, condition number = 8.45191441662197
   scaling = 0.00265954560169661, condition number = 6.55736599095592
   scaling = 0.00292550016186627, condition number = 5.1659731949198
   scaling = 0.00319145472203593, condition number = 4.23436799814725
Rescaling to 0.00319145472203593... done
Rescaling...
   scaling = 0.00265954560169661, condition number = 6.55736599095716
   scaling = 0.00290132247457812, condition number = 5.27033554761621
   scaling = 0.00319145472203593, condition number = 4.23436799814602
   scaling = 0.00351060019423953, condition number = 3.49950031178493
   scaling = 0.00382974566644312, condition number = 3.02886988520591
Rescaling to 0.00382974566644312... done
Rescaling...
   scaling = 0.00319145472203593, condition number = 4.23436799814618
   scaling = 0.00348158696949375, condition number = 3.55349052121454
   scaling = 0.00382974566644312, condition number = 3.02886988520569
   scaling = 0.00421272023308743, condition number = 3.11017097311076
   scaling = 0.00459569479973174, condition number = 3.40643118282598
Rescaling to 0.00382974566644312... done
Pre-training ended
BFGS iterations count set to 200
BFGS convergence tolerance set to 0.001
Energy weight: 1
Force weight: 1
Stress weight: 1
MTPR parallel training started
BFGS iter 0: f=0.0444957
BFGS iter 1: f=0.0444891
BFGS iter 2: f=0.0444634
BFGS iter 3: f=0.0443831
BFGS iter 4: f=0.0443624
BFGS iter 5: f=0.0442849
BFGS iter 6: f=0.0441857
BFGS iter 7: f=0.0440971
BFGS iter 8: f=0.0440672
BFGS iter 9: f=0.044007
BFGS iter 10: f=0.0439055
BFGS iter 11: f=0.0435755
BFGS iter 12: f=0.0433244
BFGS iter 13: f=0.0431003
BFGS iter 14: f=0.043007
BFGS iter 15: f=0.0427616
BFGS iter 16: f=0.0425627
BFGS iter 17: f=0.0423502
BFGS iter 18: f=0.0422441
BFGS iter 19: f=0.0420184
BFGS iter 20: f=0.0419103
BFGS iter 21: f=0.041638
BFGS iter 22: f=0.0411802
BFGS iter 23: f=0.0410351
BFGS iter 24: f=0.040801
BFGS iter 25: f=0.0406659
BFGS iter 26: f=0.0405783
BFGS iter 27: f=0.0405001
BFGS iter 28: f=0.0404241
BFGS iter 29: f=0.0403093
BFGS iter 30: f=0.0401826
BFGS iter 31: f=0.0400417
BFGS iter 32: f=0.0399283
BFGS iter 33: f=0.0398086
BFGS iter 34: f=0.0397812
BFGS iter 35: f=0.0397293
BFGS iter 36: f=0.0396951
BFGS iter 37: f=0.0396592
BFGS iter 38: f=0.0396239
BFGS iter 39: f=0.0395628
BFGS iter 40: f=0.0395021
BFGS iter 41: f=0.0394571
BFGS iter 42: f=0.0394218
BFGS iter 43: f=0.0393947
BFGS iter 44: f=0.0393624
BFGS iter 45: f=0.0392982
BFGS iter 46: f=0.039233
BFGS iter 47: f=0.039182
BFGS iter 48: f=0.0391375
BFGS iter 49: f=0.0390672
BFGS iter 50: f=0.0388706
BFGS iter 51: f=0.0388586
BFGS iter 52: f=0.038785
BFGS iter 53: f=0.0387566
BFGS iter 54: f=0.0386912
BFGS iter 55: f=0.0386359
BFGS iter 56: f=0.0385937
BFGS iter 57: f=0.0385253
BFGS iter 58: f=0.038465
BFGS iter 59: f=0.0384071
BFGS iter 60: f=0.0383508
BFGS iter 61: f=0.0382446
BFGS iter 62: f=0.0381613
BFGS iter 63: f=0.0381121
BFGS iter 64: f=0.0380456
BFGS iter 65: f=0.0379768
BFGS iter 66: f=0.0379176
BFGS iter 67: f=0.0378447
BFGS iter 68: f=0.0378092
BFGS iter 69: f=0.0377751
BFGS iter 70: f=0.0377296
BFGS iter 71: f=0.0376928
BFGS iter 72: f=0.037674
BFGS iter 73: f=0.0376613
BFGS iter 74: f=0.0376524
BFGS iter 75: f=0.0376385
BFGS iter 76: f=0.0375951
BFGS iter 77: f=0.0375764
BFGS iter 78: f=0.0375644
BFGS iter 79: f=0.0375535
BFGS iter 80: f=0.0375358
BFGS iter 81: f=0.0375212
BFGS iter 82: f=0.0374871
BFGS iter 83: f=0.0374231
BFGS iter 84: f=0.0373684
BFGS iter 85: f=0.0373042
BFGS iter 86: f=0.0372675
BFGS iter 87: f=0.0372073
BFGS iter 88: f=0.0371822
BFGS iter 89: f=0.0371524
BFGS iter 90: f=0.0371221
BFGS iter 91: f=0.0370695
BFGS iter 92: f=0.0369796
BFGS iter 93: f=0.0369507
BFGS iter 94: f=0.0369355
BFGS iter 95: f=0.036926
BFGS iter 96: f=0.0369182
BFGS iter 97: f=0.036911
BFGS iter 98: f=0.0369036
BFGS iter 99: f=0.0368798
BFGS iter 100: f=0.0364825
BFGS iter 101: f=0.0364638
BFGS iter 102: f=0.0364456
BFGS iter 103: f=0.0364329
BFGS iter 104: f=0.0363571
BFGS iter 105: f=0.036338
BFGS iter 106: f=0.0363122
BFGS iter 107: f=0.0362812
BFGS iter 108: f=0.0362221
BFGS iter 109: f=0.0361438
BFGS iter 110: f=0.0360777
BFGS iter 111: f=0.0360113
BFGS iter 112: f=0.0359074
BFGS iter 113: f=0.0358502
BFGS iter 114: f=0.0358205
BFGS iter 115: f=0.035762
BFGS iter 116: f=0.0357111
BFGS iter 117: f=0.0356661
BFGS iter 118: f=0.0356266
BFGS iter 119: f=0.0355665
BFGS iter 120: f=0.0354819
BFGS iter 121: f=0.0354232
BFGS iter 122: f=0.0353486
BFGS iter 123: f=0.0351923
BFGS iter 124: f=0.0351074
BFGS iter 125: f=0.0350142
BFGS iter 126: f=0.0349372
BFGS iter 127: f=0.0348638
BFGS iter 128: f=0.034828
BFGS iter 129: f=0.0347849
BFGS iter 130: f=0.0347509
BFGS iter 131: f=0.0347239
BFGS iter 132: f=0.0347006
BFGS iter 133: f=0.0346649
BFGS iter 134: f=0.0346105
BFGS iter 135: f=0.034583
BFGS iter 136: f=0.0345644
BFGS iter 137: f=0.0345368
BFGS iter 138: f=0.0345108
BFGS iter 139: f=0.0344904
BFGS iter 140: f=0.0344526
BFGS iter 141: f=0.0344339
BFGS iter 142: f=0.0344059
BFGS iter 143: f=0.0343789
BFGS iter 144: f=0.0343639
BFGS iter 145: f=0.0343514
BFGS iter 146: f=0.0343364
BFGS iter 147: f=0.0343244
BFGS iter 148: f=0.0343198
BFGS iter 149: f=0.0343169
BFGS iter 150: f=0.0338538
BFGS iter 151: f=0.0338026
BFGS iter 152: f=0.033742
BFGS iter 153: f=0.0337204
BFGS iter 154: f=0.0337097
BFGS iter 155: f=0.0336864
BFGS iter 156: f=0.0336555
BFGS iter 157: f=0.0335516
BFGS iter 158: f=0.0335129
BFGS iter 159: f=0.0334912
BFGS iter 160: f=0.0334691
BFGS iter 161: f=0.0334512
BFGS iter 162: f=0.0334414
BFGS iter 163: f=0.0334316
BFGS iter 164: f=0.0334209
BFGS iter 165: f=0.0334075
BFGS iter 166: f=0.0333865
BFGS iter 167: f=0.0333625
BFGS iter 168: f=0.0333486
BFGS iter 169: f=0.0333304
BFGS iter 170: f=0.0333192
BFGS iter 171: f=0.0333116
BFGS iter 172: f=0.0333047
BFGS iter 173: f=0.0332975
BFGS iter 174: f=0.0332932
BFGS iter 175: f=0.0332869
BFGS iter 176: f=0.0332777
BFGS iter 177: f=0.0332728
BFGS iter 178: f=0.0332672
BFGS iter 179: f=0.0332634
BFGS iter 180: f=0.03326
BFGS iter 181: f=0.0332548
BFGS iter 182: f=0.0332444
BFGS iter 183: f=0.0332288
BFGS iter 184: f=0.0332129
BFGS iter 185: f=0.0332072
BFGS iter 186: f=0.0332008
BFGS iter 187: f=0.0331956
BFGS iter 188: f=0.03319
BFGS iter 189: f=0.0331825
BFGS iter 190: f=0.0331702
BFGS iter 191: f=0.0331646
BFGS iter 192: f=0.0331615
BFGS iter 193: f=0.0331562
BFGS iter 194: f=0.033142
BFGS iter 195: f=0.0331284
BFGS iter 196: f=0.0331208
BFGS iter 197: f=0.0331182
BFGS iter 198: f=0.033115
BFGS iter 199: f=0.0331094
step limit reached
MTPR training ended
Rescaling...
   scaling = 0.00319145472203593, condition number = 34.9904511052153
   scaling = 0.00348158696949375, condition number = 27.0998097799445
   scaling = 0.00382974566644312, condition number = 20.5021617637758
   scaling = 0.00421272023308743, condition number = 15.5335524644221
   scaling = 0.00459569479973174, condition number = 12.0788001346008
Rescaling to 0.00459569479973174... done
Rescaling...
   scaling = 0.00382974566644312, condition number = 20.5021617637752
   scaling = 0.00417790436339249, condition number = 15.9123263632636
   scaling = 0.00459569479973174, condition number = 12.0788001346033
   scaling = 0.00505526427970492, condition number = 9.64533388858074
   scaling = 0.00551483375967809, condition number = 8.98002649364838
Rescaling to 0.00551483375967809... done
Rescaling...
   scaling = 0.00459569479973174, condition number = 12.0788001346016
   scaling = 0.00501348523607099, condition number = 9.71321663493136
   scaling = 0.00551483375967809, condition number = 8.98002649364823
   scaling = 0.0060663171356459, condition number = 8.35012324446171
   scaling = 0.00661780051161371, condition number = 7.87045312644203
Rescaling to 0.00661780051161371... done
Rescaling...
   scaling = 0.00551483375967809, condition number = 8.9800264936485
   scaling = 0.00601618228328519, condition number = 8.4007458106976
   scaling = 0.00661780051161371, condition number = 7.87045312644207
   scaling = 0.00727958056277508, condition number = 6.19483294473018
   scaling = 0.00794136061393645, condition number = 5.02987101104694
Rescaling to 0.00794136061393645... done
Rescaling...
   scaling = 0.00661780051161371, condition number = 7.87045312644183
   scaling = 0.00721941873994223, condition number = 6.32417313166903
   scaling = 0.00794136061393645, condition number = 5.02987101104652
   scaling = 0.0087354966753301, condition number = 4.09018637646996
   scaling = 0.00952963273672374, condition number = 3.47045324717711
Rescaling to 0.00952963273672374... done
Rescaling...
   scaling = 0.00794136061393645, condition number = 5.029871011047
   scaling = 0.00866330248793068, condition number = 4.16017671739371
   scaling = 0.00952963273672374, condition number = 3.47045324717669
   scaling = 0.0104825960103961, condition number = 2.99009680608043
   scaling = 0.0114355592840685, condition number = 2.68769102289866
Rescaling to 0.0114355592840685... done
Rescaling...
   scaling = 0.00952963273672374, condition number = 3.47045324717721
   scaling = 0.0103959629855168, condition number = 3.02506755459792
   scaling = 0.0114355592840685, condition number = 2.68769102289884
   scaling = 0.0125791152124753, condition number = 2.91532940690443
   scaling = 0.0137226711408822, condition number = 3.27961668030073
Rescaling to 0.0114355592840685... done

		* * * TRAIN ERRORS * * *

_________________Errors report_________________
Energy:
	Errors checked for 61 configurations
	Maximal absolute difference = 0.367723
	Average absolute difference = 0.167576
	RMS     absolute difference = 0.188457

Energy per atom:
	Errors checked for 61 configurations
	Maximal absolute difference = 0.00383045
	Average absolute difference = 0.00174558
	RMS     absolute difference = 0.00196309

Forces:
	Errors checked for 5856 atoms
	Maximal absolute difference = 1.00166
	Average absolute difference = 0.0474491
	RMS     absolute difference = 0.100953
	Max(ForceDiff) / Max(Force) = 0.19535
	RMS(ForceDiff) / RMS(Force) = 0.140976

Stresses (in eV):
	Errors checked for 61 configurations
	Maximal absolute difference = 9.83088
	Average absolute difference = 0.42773
	RMS     absolute difference = 1.4051
	Max(StresDiff) / Max(Stres) = 0.224854
	RMS(StresDiff) / RMS(Stres) = 0.196007

Stresses (in GPa):
	Errors checked for 61 configurations
	Maximal absolute difference = 0.946468
	Average absolute difference = 0.0399413
	RMS     absolute difference = 0.131225
	Max(StresDiff) / Max(Stres) = 0.237406
	RMS(StresDiff) / RMS(Stres) = 0.196726
_______________________________________________

